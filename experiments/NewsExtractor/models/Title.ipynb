{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "12956\n",
      "(12956, 2)\n",
      "No of positive examples 50\n",
      "Total number of examples 12956\n"
     ]
    }
   ],
   "source": [
    "#Data Analysis\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "trainexamples = []\n",
    "testexamples = []\n",
    "\n",
    "def loadtest(direc):\n",
    "    for each in os.listdir(direc):        \n",
    "        if '.npy' in each:\n",
    "            fids = each.split('_')[1][:-4]\n",
    "            examples = np.load(direc+'/'+each)\n",
    "            with codecs.open(direc+'/'+each[:-4]+'.json', 'r','utf-8') as infile:\n",
    "                values = json.load(infile)\n",
    "            assert(len(examples) == len(values))\n",
    "            yield examples,fids,values\n",
    "    return\n",
    "\n",
    "   \n",
    "def load(direc):\n",
    "    examples = []\n",
    "    fids  = []\n",
    "    values = []\n",
    "    for each in os.listdir(direc):        \n",
    "        try:\n",
    "            if '.npy' in each:\n",
    "                fids.append(each.split('_')[1][:-4])\n",
    "                examples.extend(np.load(direc+'/'+each))\n",
    "                with open(direc+'/'+each[:-4]+'.json', 'r') as infile:\n",
    "                    values.extend(json.load(infile))\n",
    "        except:\n",
    "            continue\n",
    "    return examples,fids,values\n",
    "\n",
    "trainexamples, trainfids, trainvalues = load('../../../data/Titlefeature/train')\n",
    "\n",
    "trainlabels, trainfeatures = [], []\n",
    "for each in trainexamples:\n",
    "    trainfeatures.append(each[1:])\n",
    "    trainlabels.append(each[0])\n",
    "\n",
    "assert(len(trainvalues)==len(trainlabels))\n",
    "print len(trainfeatures[0])\n",
    "print len(trainfeatures)\n",
    "\n",
    "X = np.array(trainfeatures)\n",
    "print X.shape\n",
    "Y = map(lambda x: 1 if x==1 else 0, trainlabels )\n",
    "Y = np.array(Y)\n",
    "print 'No of positive examples %d' %Y.nonzero()[0].shape[0]\n",
    "print 'Total number of examples %d'%Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "FeatureNames\n",
      "isbestTitle\n",
      "isheading\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "#################### SVC  ###############################\n",
      "#################### LOGISTIC REGRESSION ###############################\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  41 jobs       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.0s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.0s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.0s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.0s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.0s\n",
      "RandomizedSearchCV took 0.00 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.804 (std: 0.057)\n",
      "Parameters: {'C': 1000, 'class_weight': {0: 1, 1: 15}}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.804 (std: 0.057)\n",
      "Parameters: {'C': 50, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.804 (std: 0.057)\n",
      "Parameters: {'C': 0.7, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Continue ??\n",
      "d\n",
      "#################### RANDOM FOREST ###############################\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=gini, max_depth=3, min_samples_leaf=4 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=gini, max_depth=3, min_samples_leaf=4 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=gini, max_depth=3, min_samples_leaf=4 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=gini, max_depth=3, min_samples_leaf=4 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=gini, max_depth=3, min_samples_leaf=4 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=gini, max_depth=3, min_samples_leaf=4 -   0.0s\n",
      "[CV] min_samples_split=4, bootstrap=True, criterion=gini, max_depth=None, min_samples_leaf=7 \n",
      "[CV]  min_samples_split=4, bootstrap=True, criterion=gini, max_depth=None, min_samples_leaf=7 -   0.0s\n",
      "[CV] min_samples_split=4, bootstrap=True, criterion=gini, max_depth=None, min_samples_leaf=7 \n",
      "[CV]  min_samples_split=4, bootstrap=True, criterion=gini, max_depth=None, min_samples_leaf=7 -   0.0s\n",
      "[CV] min_samples_split=4, bootstrap=True, criterion=gini, max_depth=None, min_samples_leaf=7 \n",
      "[CV]  min_samples_split=4, bootstrap=True, criterion=gini, max_depth=None, min_samples_leaf=7 -   0.0s\n",
      "[CV] min_samples_split=1, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=1, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=1, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=1, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=1, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=1, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=6, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=10 \n",
      "[CV]  min_samples_split=6, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=10 -   0.0s\n",
      "[CV] min_samples_split=6, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=10 \n",
      "[CV]  min_samples_split=6, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=10 -   0.0s\n",
      "[CV] min_samples_split=6, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=10 \n",
      "[CV]  min_samples_split=6, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=10 -   0.0s\n",
      "[CV] min_samples_split=5, bootstrap=True, criterion=gini, max_depth=3, min_samples_leaf=6 \n",
      "[CV]  min_samples_split=5, bootstrap=True, criterion=gini, max_depth=3, min_samples_leaf=6 -   0.0s\n",
      "[CV] min_samples_split=5, bootstrap=True, criterion=gini, max_depth=3, min_samples_leaf=6 \n",
      "[CV]  min_samples_split=5, bootstrap=True, criterion=gini, max_depth=3, min_samples_leaf=6 -   0.0s\n",
      "[CV] min_samples_split=5, bootstrap=True, criterion=gini, max_depth=3, min_samples_leaf=6 \n",
      "[CV]  min_samples_split=5, bootstrap=True, criterion=gini, max_depth=3, min_samples_leaf=6 -   0.0s\n",
      "[CV] min_samples_split=7, bootstrap=True, criterion=entropy, max_depth=None, min_samples_leaf=9 \n",
      "[CV]  min_samples_split=7, bootstrap=True, criterion=entropy, max_depth=None, min_samples_leaf=9 -   0.0s\n",
      "[CV] min_samples_split=7, bootstrap=True, criterion=entropy, max_depth=None, min_samples_leaf=9 \n",
      "[CV]  min_samples_split=7, bootstrap=True, criterion=entropy, max_depth=None, min_samples_leaf=9 -   0.0s\n",
      "[CV] min_samples_split=7, bootstrap=True, criterion=entropy, max_depth=None, min_samples_leaf=9 \n",
      "[CV]  min_samples_split=7, bootstrap=True, criterion=entropy, max_depth=None, min_samples_leaf=9 -   0.0s\n",
      "[CV] min_samples_split=1, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=1, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=1, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=1, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=1, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=1, bootstrap=True, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=None, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=None, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=None, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=None, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=None, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=None, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 \n",
      "[CV]  min_samples_split=2, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=5 -   0.0s\n",
      "[CV] min_samples_split=5, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=1 \n",
      "[CV]  min_samples_split=5, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=1 -   0.0s\n",
      "[CV] min_samples_split=5, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=1 \n",
      "[CV]  min_samples_split=5, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=1 -   0.0s\n",
      "[CV] min_samples_split=5, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=1 \n",
      "[CV]  min_samples_split=5, bootstrap=False, criterion=entropy, max_depth=3, min_samples_leaf=1 -   0.0s\n",
      "RandomizedSearchCV took 0.81 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.791 (std: 0.044)\n",
      "Parameters: {'min_samples_split': 4, 'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 7}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.791 (std: 0.044)\n",
      "Parameters: {'min_samples_split': 6, 'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.791 (std: 0.044)\n",
      "Parameters: {'min_samples_split': 5, 'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 6}\n",
      "\n",
      "BestParams and score\n",
      "[({'C': 1000, 'class_weight': {0: 1, 1: 15}}, 0.80405935013838692), ({'min_samples_split': 4, 'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 7}, 0.79068028430386395)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('../../../data/Titlefeature/train/featurenames.json') as infile:\n",
    "    featurenames = json.load(infile)\n",
    "assert(len(featurenames) == len(trainfeatures[0]))\n",
    "\n",
    "\n",
    "################ ML methods ######################################\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "d = dict(zip(featurenames,range(len(featurenames))))\n",
    "print '-----------------'*10\n",
    "print 'FeatureNames'\n",
    "for each in d.keys():\n",
    "    print each\n",
    "print '-----------------'*10\n",
    "###################################################################################################################\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        if i == 0:\n",
    "            bestparams = (score.parameters,score.mean_validation_score)\n",
    "        print(\"\")\n",
    "    return bestparams\n",
    "\n",
    "def getf1score(estimator, X, Y):\n",
    "    #return recall_score(estimator.predict(X),Y)\n",
    "    return f1_score(estimator.predict(X),Y)\n",
    "\n",
    "\n",
    "\n",
    "clf1 = SVC(C=1.0)\n",
    "clf2 = LogisticRegression(penalty='l2', random_state=4,C=1.0)\n",
    "clf3 = RandomForestClassifier(n_estimators=20)\n",
    "s3fold = StratifiedKFold(y=Y, n_folds=5,\n",
    "                                         shuffle=True, random_state=2)\n",
    "bestparams = []\n",
    "\n",
    "C = [0.001, 0.001, 0.1, 0.7, 0.5, 0.6, 0.9, 1, 2, 5, 7, 10,50, 70, 100,1000]\n",
    "gamma = [0.00001, 0.0001,0.001, 0.01, 0.1]\n",
    "class_weights = [{0:1,1:1},{0:1,1:5},{0:1,1:10},{0:1,1:15},{0:1,1:20}]\n",
    "\n",
    "param_dist = {\"C\": C, \"gamma\":gamma, \"class_weight\":class_weights}\n",
    "\n",
    "Xnew = X\n",
    "\n",
    "\n",
    "print '#################### SVC  ###############################'\n",
    "np.random.seed(5)\n",
    "# # run randomized search\n",
    "n_iter_search = 20\n",
    "# random_search = RandomizedSearchCV(clf1, param_distributions=param_dist, scoring=getf1score,\n",
    "#                                    verbose=2, cv=s3fold )\n",
    "# start = time()\n",
    "# random_search.fit(Xnew, Y)\n",
    "# print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "#       \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "# bestparams.append(report(random_search.grid_scores_))\n",
    "# print 'Continue ??'\n",
    "# raw_input()\n",
    "\n",
    "param_dist = {\"C\": C,\"class_weight\": class_weights}\n",
    "print '#################### LOGISTIC REGRESSION ###############################'\n",
    "random_search = RandomizedSearchCV(clf2, param_distributions=param_dist, scoring=getf1score,\n",
    "                                   verbose=2 ,cv=s3fold)\n",
    "\n",
    "random_search.fit(Xnew, Y)\n",
    "start = time()\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "bestparams.append(report(random_search.grid_scores_))\n",
    "print 'Continue ??'\n",
    "raw_input()\n",
    "\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "print '#################### RANDOM FOREST ###############################'\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "random_search = RandomizedSearchCV(clf3, param_distributions=param_dist, scoring=getf1score,\n",
    "                                   verbose=2 )\n",
    "\n",
    "\n",
    "start = time()\n",
    "random_search.fit(Xnew, Y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "bestparams.append(report(random_search.grid_scores_))\n",
    "print 'BestParams and score'\n",
    "print bestparams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758620689655\n",
      "0.666666666667\n",
      "33 25\n",
      "\n",
      "Pickling...\n",
      "[[ 8.06406635  3.72745336]] [-5.92377101]\n",
      "Done pickling..\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import recall_score\n",
    "random.seed(124)  \n",
    "np.random.seed(124)\n",
    "# clf = RandomForestClassifier(n_estimators=20, bootstrap=True, min_samples_leaf=1, \n",
    "#                              min_samples_split=1, criterion='gini', max_features=5, max_depth=None)\n",
    "clf = LogisticRegression(**{'C': 1000, 'class_weight': {0: 1, 1: 15}})\n",
    "\n",
    "rpos = filter(lambda x: Y[x]>0, range(Y.shape[0]))\n",
    "rneg = filter(lambda x: Y[x]==0, range(Y.shape[0]))\n",
    "\n",
    "random.shuffle(rpos)\n",
    "random.shuffle(rneg)\n",
    "\n",
    "rtrain = rpos[:int(len(rpos)/2)]+rneg[:int(len(rneg)/3)]\n",
    "rtest = rpos[int(len(rpos)/2):]+rneg[int(len(rneg)/3):]\n",
    "random.shuffle(rtrain)\n",
    "random.shuffle(rtest)\n",
    "\n",
    "\n",
    "clf.fit(X[rtrain,:],Y[rtrain])\n",
    "print f1_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "print recall_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "print len(clf.predict(X[rtest,:]).nonzero()[0]),len(Y[rtest].nonzero()[0])\n",
    "print \n",
    "\n",
    "\n",
    "print 'Pickling...'\n",
    "clf.fit(X,Y)\n",
    "print clf.coef_, clf.intercept_\n",
    "pickle.dump(clf, file('../../../data/Titlefeature/train/Title.classifier','w'))\n",
    "print 'Done pickling..'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TitleClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Predicts for a single news article only\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self,X):        \n",
    "        assert(X.shape[1] == 2)        \n",
    "        rowno = 0\n",
    "        res = -1\n",
    "        gotit = False\n",
    "        for goodmatch,isheading in X:\n",
    "            \n",
    "            if goodmatch == 1 and isheading==1:\n",
    "                res = rowno\n",
    "                \n",
    "                break;\n",
    "            if isheading == 1 and not gotit:\n",
    "                res = rowno\n",
    "                gotit  = True\n",
    "            rowno+=1\n",
    "        Y = [0]*X.shape[0]\n",
    "        print res\n",
    "        if res>=0:\n",
    "            Y[res] = 1\n",
    "        return Y\n",
    "            \n",
    "TestCheck = TitleClassifier()\n",
    "import pickle\n",
    "pickle.dump( TestCheck, file('Best_title.dat','wb'))\n",
    "TC = pickle.load(file('Best_title.dat','rb'))\n",
    "for x,y,v in loadtest('../../../../data/Titlefeature/cv1/test'):\n",
    "    Y = TC.predict(np.array(x).transpose()[1:,].transpose())\n",
    "    print '--**'*10\n",
    "    title = ''\n",
    "    for i,e in enumerate(Y):\n",
    "        if e == 1:\n",
    "            title+=v[i]\n",
    "    print title\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
