{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11520\n"
     ]
    }
   ],
   "source": [
    "#Data Analysis\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "trainexamples = []\n",
    "testexamples = []\n",
    "\n",
    "def loadtest(direc):\n",
    "    for each in os.listdir(direc):        \n",
    "        if '.npy' in each:\n",
    "            fids = each.split('_')[1][:-4]\n",
    "            examples = np.load(direc+'/'+each)\n",
    "            with open(direc+'/'+each[:-4]+'.json', 'r') as infile:\n",
    "                values = json.load(infile)\n",
    "            yield examples,fids,values\n",
    "    return\n",
    "\n",
    "   \n",
    "def load(direc):\n",
    "    examples = []\n",
    "    fids  = []\n",
    "    values = []\n",
    "    for each in os.listdir(direc):        \n",
    "        try:\n",
    "            if '.npy' in each:\n",
    "                fids.append(each.split('_')[1][:-4])\n",
    "                examples.extend(np.load(direc+'/'+each))\n",
    "                with open(direc+'/'+each[:-4]+'.json', 'r') as infile:\n",
    "                    values.extend(json.load(infile))\n",
    "        except:\n",
    "            continue\n",
    "    return examples,fids,values\n",
    "\n",
    "trainexamples, trainfids, trainvalues = load('../../../../data/bowfeature/cv1/train')\n",
    "\n",
    "trainlabels, trainfeatures = [], []\n",
    "for each in trainexamples:\n",
    "    trainfeatures.append(each[1:])\n",
    "    trainlabels.append(each[0])\n",
    "\n",
    "testexamples, testfids, testvalues = load('../../../../data/bowfeature/cv1/test')\n",
    "testfeatures, testlabels = [], []\n",
    "for each in testexamples:\n",
    "    testfeatures.append(each[1:])\n",
    "    testlabels.append(each[0])\n",
    "assert(len(trainvalues)==len(trainlabels))\n",
    "assert(len(testvalues)==len(testlabels))\n",
    "print len(trainfeatures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11520\n",
      "(13635, 11520)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((1.7759502635855684e-15, 11172), u'BOW_weapon'),\n",
       " ((1.7759502635855684e-15, 11213), u'BOW_wellness'),\n",
       " ((1.7759502635855684e-15, 11234), u'BOW_whale'),\n",
       " ((1.7759502635855684e-15, 11258), u'BOW_wi'),\n",
       " ((1.7759502635855684e-15, 11262), u'BOW_wide'),\n",
       " ((1.7759502635855684e-15, 11265), u'BOW_widow'),\n",
       " ((1.7759502635855684e-15, 11291), u'BOW_wine'),\n",
       " ((1.7759502635855684e-15, 11298), u'BOW_winning'),\n",
       " ((1.7759502635855684e-15, 11351), u'BOW_wood'),\n",
       " ((1.7759502635855684e-15, 11368), u'BOW_working'),\n",
       " ((1.7759502635855684e-15, 11451), u'BOW_yall'),\n",
       " ((1.7759502635855684e-15, 11456), u'BOW_yards'),\n",
       " ((1.7759502635855684e-15, 11458), u'BOW_yeah'),\n",
       " ((1.7759502635855684e-15, 11498), u'BOW_zero'),\n",
       " ((1.7759502635855684e-15, 11507), u'BOW_zolciak'),\n",
       " ((1.7763568394002505e-15, 2203), u'BOW_contests'),\n",
       " ((1.7763568394002505e-15, 3734), u'BOW_featured'),\n",
       " ((1.7763568394002505e-15, 6771), u'BOW_nation'),\n",
       " ((1.7763568394002505e-15, 10197), u'BOW_technology'),\n",
       " ((1.7763568394002505e-15, 11364), u'BOW_work')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select k best\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "#interested in negative class only\n",
    "#boilerplate = map(lambda x: 0 if x>0 else 1 , trainlabels)\n",
    "\n",
    "new_trainfeatures = []\n",
    "for i,each in enumerate(trainfeatures):\n",
    "    if trainlabels[i]==0:\n",
    "        new_trainfeatures.append(each)\n",
    "        \n",
    "print len(new_trainfeatures[0])\n",
    "tf = np.array(new_trainfeatures)\n",
    "print tf.shape\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import json\n",
    "with open('../../../../data/bowfeature/cv1/train/featurenames.json','r') as infile:\n",
    "    data = json.load(infile)\n",
    "res =[]\n",
    "for i in range(tf.shape[1]):\n",
    "    res.append((matthews_corrcoef([1]*len(new_trainfeatures), tf.transpose()[i,:].transpose()),i))\n",
    "sorted(zip(res,data))[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2382\n",
      "credit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print data.index('BOW_credit')\n",
    "\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "print stemmer.stem(\"credited\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainlabels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-797c2cb33921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#expolaratory analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#does feature space capture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mtrainlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainlabels' is not defined"
     ]
    }
   ],
   "source": [
    "#expolaratory analysis\n",
    "#does feature space capture \n",
    "print trainlabels.count(0),trainlabels.count(1), trainlabels.count(2)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA(n_components=2)\n",
    "trainfeatures1 = normalize(trainfeatures)\n",
    "X = pca.fit_transform(trainfeatures1)\n",
    "assert(X.shape[1] == 2)\n",
    "\n",
    "d = {0:[],1:[],2:[],3:[]}\n",
    "for i,each in enumerate(trainexamples):\n",
    "    d[each[0]].append(X[i,:])\n",
    "\n",
    "x,y = zip(*d[0])\n",
    "plt.plot(x,y,'bo')\n",
    "x,y = zip(*d[1])\n",
    "plt.plot(x,y,'go')\n",
    "x,y = zip(*d[2])\n",
    "plt.plot(x,y,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "print mutual_info_score([1,1,0], [0,0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
