{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "12956\n",
      "(12956, 169)\n",
      "No of positive examples 508\n",
      "Total number of examples 12956\n"
     ]
    }
   ],
   "source": [
    "#Data Analysis\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "trainexamples = []\n",
    "testexamples = []\n",
    "\n",
    "def loadtest(direc):\n",
    "    for each in os.listdir(direc):        \n",
    "        if '.npy' in each:\n",
    "            fids = each.split('_')[1][:-4]\n",
    "            examples = np.load(direc+'/'+each)\n",
    "            with codecs.open(direc+'/'+each[:-4]+'.json', 'r','utf-8') as infile:\n",
    "                values = json.load(infile)\n",
    "            assert(len(examples) == len(values))\n",
    "            yield examples,fids,values\n",
    "    return\n",
    "\n",
    "   \n",
    "def load(direc):\n",
    "    examples = []\n",
    "    fids  = []\n",
    "    values = []\n",
    "    for each in os.listdir(direc):        \n",
    "        try:\n",
    "            if '.npy' in each:\n",
    "                fids.append(each.split('_')[1][:-4])\n",
    "                examples.extend(np.load(direc+'/'+each))\n",
    "                with open(direc+'/'+each[:-4]+'.json', 'r') as infile:\n",
    "                    values.extend(json.load(infile))\n",
    "        except:\n",
    "            continue\n",
    "    return examples,fids,values\n",
    "\n",
    "trainexamples, trainfids, trainvalues = load('../../../data/Contentfeature/train')\n",
    "\n",
    "trainlabels, trainfeatures = [], []\n",
    "for each in trainexamples:\n",
    "    trainfeatures.append(each[1:])\n",
    "    trainlabels.append(each[0])\n",
    "\n",
    "assert(len(trainvalues)==len(trainlabels))\n",
    "print len(trainfeatures[0])\n",
    "print len(trainfeatures)\n",
    "\n",
    "X = np.array(trainfeatures)\n",
    "print X.shape\n",
    "Y = map(lambda x: 1 if x==2 else 0, trainlabels )\n",
    "Y = np.array(Y)\n",
    "print 'No of positive examples %d' %Y.nonzero()[0].shape[0]\n",
    "print 'Total number of examples %d'%Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "FeatureNames\n",
      "next_tag=footer\n",
      "ancestorTag=i\n",
      "next_tag=fieldset\n",
      "ancestorTag=b\n",
      "ancestorTag=a\n",
      "data-font-size=12px\n",
      "next_tag=iframe\n",
      "next_tag=nav\n",
      "word_count\n",
      "ancestorTag=p\n",
      "parent_tag=center\n",
      "parent_tag=blockquote\n",
      "next_tag=noscript\n",
      "parent_tag=cite\n",
      "previous_tag=ul\n",
      "parent_tag=span\n",
      "next_tag=button\n",
      "previous_tag=td\n",
      "ancestorTag=input\n",
      "ancestorTag=blockquote\n",
      "functional_word_ratio\n",
      "previous_tag=b\n",
      "previous_tag=a\n",
      "next_tag=time\n",
      "previous_tag=fieldset\n",
      "previous_tag=dd\n",
      "previous_tag=i\n",
      "previous_tag=p\n",
      "next_tag=select\n",
      "parent_tag=td\n",
      "previous_tag=dt\n",
      "parent_tag=time\n",
      "next_tag=cite\n",
      "next_tag=ol\n",
      "parent_tag=i\n",
      "next_tag=td\n",
      "previous_tag=label\n",
      "next_tag=option\n",
      "class=header\n",
      "previous_tag=li\n",
      "next_tag=figure\n",
      "next_tag=table\n",
      "next_tag=b\n",
      "next_tag=a\n",
      "next_tag=img\n",
      "next_tag=i\n",
      "ancestorTag=header\n",
      "previous_tag=span\n",
      "next_tag=p\n",
      "parent_tag=legend\n",
      "parent_tag=div\n",
      "parent_tag=dt\n",
      "previous_tag=strong\n",
      "next_tag=__empty__\n",
      "ancestorTag=em\n",
      "parent_tag=br\n",
      "previous_tag=time\n",
      "parent_tag=li\n",
      "next_tag=hr\n",
      "previous_tag=center\n",
      "parent_tag=em\n",
      "previous_tag=__empty__\n",
      "previous_tag=input\n",
      "previous_tag=small\n",
      "next_tag=comments\n",
      "ancestorTag=label\n",
      "next_tag=script\n",
      "ancestorTag=span\n",
      "ancestorTag=option\n",
      "ancestorTag=td\n",
      "ancestorTag=time\n",
      "previous_tag=option\n",
      "ancestorTag=dd\n",
      "parent_tag=option\n",
      "parent_tag=p\n",
      "data-font-size=16px\n",
      "next_tag=h4\n",
      "next_tag=h5\n",
      "parent_tag=input\n",
      "ancestorTag=div\n",
      "next_tag=h1\n",
      "next_tag=h2\n",
      "next_tag=h3\n",
      "ancestorTag=li\n",
      "ancestorTag=dt\n",
      "next_tag=meta\n",
      "next_tag=span\n",
      "parent_tag=a\n",
      "ancestorTag=button\n",
      "previous_tag=style\n",
      "previous_tag=abbr\n",
      "parent_tag=label\n",
      "parent_tag=commentscount\n",
      "previous_tag=legend\n",
      "next_tag=br\n",
      "next_tag=label\n",
      "parent_tag=small\n",
      "functional_word_count\n",
      "ancestorTag=textarea\n",
      "previous_tag=img\n",
      "ancestorTag=abbr\n",
      "previous_tag=h4\n",
      "previous_tag=h5\n",
      "previous_tag=h6\n",
      "parent_tag=sup\n",
      "previous_tag=h1\n",
      "previous_tag=h2\n",
      "previous_tag=h3\n",
      "next_tag=textarea\n",
      "next_tag=small\n",
      "parent_tag=abbr\n",
      "ancestorTag=comment()\n",
      "next_tag=article\n",
      "data-font-size=14px\n",
      "previous_tag=div\n",
      "previous_tag=form\n",
      "parent_tag=strong\n",
      "ancestorTag=cite\n",
      "previous_tag=button\n",
      "previous_tag=figcaption\n",
      "next_tag=abbr\n",
      "ancestorTag=br\n",
      "ancestorTag=strong\n",
      "previous_tag=header\n",
      "previous_tag=hr\n",
      "class=content\n",
      "previous_tag=em\n",
      "mspam\n",
      "next_tag=div\n",
      "next_tag=header\n",
      "parent_tag=dd\n",
      "ancestorTag=h4\n",
      "ancestorTag=h5\n",
      "ancestorTag=h6\n",
      "parent_tag=textarea\n",
      "ancestorTag=h1\n",
      "ancestorTag=h2\n",
      "ancestorTag=h3\n",
      "next_tag=strong\n",
      "next_tag=figcaption\n",
      "next_tag=li\n",
      "previous_tag=aside\n",
      "parent_tag=comment\n",
      "ancestorTag=comments-count\n",
      "previous_tag=section\n",
      "previous_tag=address\n",
      "next_tag=ul\n",
      "next_tag=dd\n",
      "next_tag=menu\n",
      "parent_tag=button\n",
      "previous_tag=blockquote\n",
      "parent_tag=h\n",
      "ancestorTag=small\n",
      "next_tag=aside\n",
      "previous_tag=script\n",
      "previous_tag=figure\n",
      "ancestorTag=center\n",
      "previous_tag=br\n",
      "previous_tag=meta\n",
      "next_tag=input\n",
      "ancestorTag=sup\n",
      "ancestorTag=legend\n",
      "next_tag=form\n",
      "parent_tag=b\n",
      "previous_tag=noscript\n",
      "next_tag=section\n",
      "next_tag=style\n",
      "parent_tag=header\n",
      "next_tag=em\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "#################### SVC  ###############################\n",
      "#################### LOGISTIC REGRESSION ###############################\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.0s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.2s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.1s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.0s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.2s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.1s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.1s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.0s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.1s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.1s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.1s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  41 jobs       | elapsed:    3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.2s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.1s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.2s\n",
      "RandomizedSearchCV took 0.00 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.566 (std: 0.010)\n",
      "Parameters: {'C': 0.7, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.562 (std: 0.012)\n",
      "Parameters: {'C': 50, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.560 (std: 0.013)\n",
      "Parameters: {'C': 1000, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Continue ??\n",
      "d\n",
      "#################### RANDOM FOREST ###############################\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gowthamrang/anaconda2/lib/python2.7/site-packages/scikit_learn-0.16.1-py2.7-linux-x86_64.egg/sklearn/metrics/classification.py:960: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None -   0.2s\n",
      "[CV] bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None -   0.2s\n",
      "[CV] bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None \n",
      "[CV]  bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None -   0.1s\n",
      "[CV] bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None \n",
      "[CV]  bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None -   0.3s\n",
      "[CV] bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None \n",
      "[CV]  bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None -   0.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 -   0.0s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 -   0.0s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 -   0.0s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 -   0.0s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 -   0.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 3.83 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.394 (std: 0.057)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.391 (std: 0.053)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'gini', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.386 (std: 0.041)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 4, 'criterion': 'entropy', 'max_features': 3, 'max_depth': None}\n",
      "\n",
      "BestParams and score\n",
      "[({'C': 0.7, 'class_weight': {0: 1, 1: 5}}, 0.56571782502409707), ({'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}, 0.3936540271163495)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('../../../data/Contentfeature/train/featurenames.json') as infile:\n",
    "    featurenames = json.load(infile)\n",
    "assert(len(featurenames) == len(trainfeatures[0]))\n",
    "\n",
    "\n",
    "################ ML methods ######################################\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "d = dict(zip(featurenames,range(len(featurenames))))\n",
    "print '-----------------'*10\n",
    "print 'FeatureNames'\n",
    "for each in d.keys():\n",
    "    print each\n",
    "print '-----------------'*10\n",
    "###################################################################################################################\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        if i == 0:\n",
    "            bestparams = (score.parameters,score.mean_validation_score)\n",
    "        print(\"\")\n",
    "    return bestparams\n",
    "\n",
    "def getf1score(estimator, X, Y):\n",
    "    #return recall_score(estimator.predict(X),Y)\n",
    "    return f1_score(estimator.predict(X),Y)\n",
    "\n",
    "\n",
    "\n",
    "clf1 = SVC(C=1.0)\n",
    "clf2 = LogisticRegression(penalty='l2', random_state=4,C=1.0)\n",
    "clf3 = RandomForestClassifier(n_estimators=20)\n",
    "s3fold = StratifiedKFold(y=Y, n_folds=5,\n",
    "                                         shuffle=True, random_state=2)\n",
    "bestparams = []\n",
    "\n",
    "C = [0.001, 0.001, 0.1, 0.7, 0.5, 0.6, 0.9, 1, 2, 5, 7, 10,50, 70, 100,1000]\n",
    "gamma = [0.00001, 0.0001,0.001, 0.01, 0.1]\n",
    "class_weights = [{0:1,1:1},{0:1,1:5},{0:1,1:10},{0:1,1:15},{0:1,1:20}]\n",
    "\n",
    "param_dist = {\"C\": C, \"gamma\":gamma, \"class_weight\":class_weights}\n",
    "\n",
    "Xnew = X\n",
    "\n",
    "\n",
    "print '#################### SVC  ###############################'\n",
    "np.random.seed(5)\n",
    "# # run randomized search\n",
    "n_iter_search = 20\n",
    "# random_search = RandomizedSearchCV(clf1, param_distributions=param_dist, scoring=getf1score,\n",
    "#                                    verbose=2, cv=s3fold )\n",
    "# start = time()\n",
    "# random_search.fit(Xnew, Y)\n",
    "# print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "#       \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "# bestparams.append(report(random_search.grid_scores_))\n",
    "# print 'Continue ??'\n",
    "# raw_input()\n",
    "\n",
    "param_dist = {\"C\": C,\"class_weight\": class_weights}\n",
    "print '#################### LOGISTIC REGRESSION ###############################'\n",
    "random_search = RandomizedSearchCV(clf2, param_distributions=param_dist, scoring=getf1score,\n",
    "                                   verbose=2 ,cv=s3fold)\n",
    "\n",
    "random_search.fit(Xnew, Y)\n",
    "start = time()\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "bestparams.append(report(random_search.grid_scores_))\n",
    "print 'Continue ??'\n",
    "raw_input()\n",
    "\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "print '#################### RANDOM FOREST ###############################'\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "random_search = RandomizedSearchCV(clf3, param_distributions=param_dist, scoring=getf1score,\n",
    "                                   verbose=2 )\n",
    "\n",
    "\n",
    "start = time()\n",
    "random_search.fit(Xnew, Y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "bestparams.append(report(random_search.grid_scores_))\n",
    "print 'BestParams and score'\n",
    "print bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Needs more negative samples to distinguish\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dae36dad7940>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Random Forest Needs more negative samples to distinguish'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gowthamrang/anaconda2/lib/python2.7/site-packages/scikit_learn-0.16.1-py2.7-linux-x86_64.egg/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m                 )\n\u001b[0;32m   1038\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gowthamrang/anaconda2/lib/python2.7/site-packages/scikit_learn-0.16.1-py2.7-linux-x86_64.egg/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \"\"\"\n\u001b[0;32m    786\u001b[0m     \u001b[1;31m# FIXME Remove case insensitivity in 0.18 ---------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m     \u001b[0mloss_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     msg = (\"loss='%s' has been deprecated in favor of \"\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "random.seed(124)  \n",
    "np.random.seed(124)\n",
    "clf = LogisticRegression(**{'C': 0.7, 'class_weight': {0: 1, 1: 5}})\n",
    "\n",
    "rpos = filter(lambda x: Y[x]>0, range(Y.shape[0]))\n",
    "rneg = filter(lambda x: Y[x]==0, range(Y.shape[0]))\n",
    "\n",
    "random.shuffle(rpos)\n",
    "random.shuffle(rneg)\n",
    "\n",
    "rtrain = rpos[:int(len(rpos)/2)]+rneg[:int(len(rneg)/3)]\n",
    "rtest = rpos[int(len(rpos)/2):]+rneg[int(len(rneg)/3):]\n",
    "random.shuffle(rtrain)\n",
    "random.shuffle(rtest)\n",
    "print 'Random Forest Needs more negative samples to distinguish'\n",
    "\n",
    "clf.fit(X[rtrain,:],Y[rtrain])\n",
    "print f1_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "print recall_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "print len(clf.predict(X[rtest,:]).nonzero()[0]),len(Y[rtest].nonzero()[0])\n",
    "print \n",
    "\n",
    "print 'Pickling...'\n",
    "clf.fit(X,Y)\n",
    "pickle.dump(clf, file('./../../data/Contentfeature/train/Content.classifier','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also, photographer Shawn Ouellette’s video “A Mother’s Wish: Dying at Home” won an Emmy award in the health/science feature segment category. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The newspaper’s staff members were nominated for a total of five regional Emmy awards this year. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Kimball and former Press Herald videographer Amelia Kunhardt were nominated in the feature news/light feature category for “Old Man of the Sea,” a story about 84-year-old lobsterman Andy Gove, who has no plans to retire. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Kunhardt also was nominated in the societal concerns category for “The Right Place at the Right Time,” a report on a Portland motel clerk who in 2002 was credited with helping police identify a fugitive couple who were wanted for the murder of their infant daughter. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Kunhardt’s video essay “Sand, Surf and Sun,” which profiles the oceanfront resort town of Old Orchard Beach, was nominated for best video essay. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Kunhardt won a Boston/New England Emmy award in 2014 for a documentary she produced on the shooting of an 18-year-old by a Maine state trooper in West Paris. “Three Shots on Roy Road” won in the societal concerns category. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 11363 Monday, Sept. 14, 2015 [ 0.  0.  0.]\n",
      "k\n",
      "AIKEN CO., S.C. (WRDW) -- News 12 arrived on scene of where the accident was reported and did not find an accident. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "We have reached out to South Carolina Highway Patrol for more information. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "AIKEN CO., S.C. (WRDW) -- Aiken County dispatch confirms deputies are on the scene of an accident on the Palmetto Parkway near the state line. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "A witness tells News 12, the front of a car is wedged under a semi. He says he saw an ambulance leave the scene, but dispatch could not confirm if anyone was injured. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 11586 RAPID CITY, S.D. (AP) - Rapid City police say an officer responding to a domestic assault call fatally shot a male suspect who lunged at him with a \"blunt object.\" [ 0.  0.  0.]\n",
      "l\n",
      "The Rapid City Police Department said in a news release that police were dispatched Tuesday night to a residence where a domestic assault was taking place. The department says the male suspect and a female victim were inside. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "According to police, officers tried multiple times to make contact with the suspect, and they forced their way inside after the suspect refused to open the door. Police say the suspect then lunged at an officer with a blunt object raised over his head, and the officer shot him. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Police say the suspect was pronounced dead at the scene, and no officers or bystanders were hurt. The officer was placed on administrative leave, per department policy. [ 0.  0.  0.]\n",
      "Nailed it\n",
      " The U.S. Department of Justice has awarded the City of Killeen a $1.625 million Community Oriented Policing Services grant that will fund 13 new police officers, U.S. Rep. John Carter, R-Round Rock, announced Tuesday.                                              [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The COPS grants are awarded to local law enforcement agencies to fund new officers to help with community crime prevention efforts. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "A total of $113 million was awarded to 209 agencies during the 2015 grant cycle, Carter said. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The Killeen Police Department received a $1.8 million COPS grant in 2010 for 10 officers and another $1.5 million in 2014 for 13 officers. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 11787 Star Plus was the number one channel since a while but Colors TV has taken over. Here is the BARC report for week 36! [ 0.  0.  0.]\n",
      "k\n",
      " was the number one show last week and is this week as well! [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Last week, Star Plus had regained it’s spot as the number one spot and outdone Colors TV. But the latter is on top once again, followed by Star Plus. Kumkum Bhagya is the number one show yet again, followed by Meri Aashiqui Tumse Hi. New show Swaragini is slowly making it’s mark in the TRP charts and has earned the 3rd position this time. Star Plus’s Yeh Hai Mohabbatein has not seen any major improvement and shockingly, ZEE TV’s Qubool Hai is one of the lowest ranking shows this week. Here’s the  [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 11791 BARC report  [ 0.  0.  0.]\n",
      "o\n",
      "0 1 11792 for week 36! [ 0.  0.  0.]\n",
      "9\n",
      "Top ten shows (TRPs) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 11794 Kumkum Bhagya  4.8 (4.5) [ 0.  0.  0.]\n",
      "0\n",
      "Meri Aashiqui Meri Aashiqui 4 (3.8) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Swaragini 3.8 (3.6), Sasural Simar 3.6 (3.6,  Saath Nibhaana Saathiya 3.8 (3.6) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Udaan 3.7 (3.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Balika Vadhu 3.3 (3),  Yeh Hai Mohabbatein 3.3 (3.1) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Ashoka Samrat 3.1, (3.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Yeh Rishta Kya Kehlata Hai  2.5 (2.7), Tarak Mehta Ka Oolta Chashma 2.5, (2.6) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Suhani Si Ek Ladki  2.4 (2.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Thapki Pyar Ki 2.2, (2.1) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Jamai  Raja 2.1 (1.9), Satrangi Sasural  2.1 (2.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Reality Shows (TRPs) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Comedy Nights Bachao 3.4 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Comedy Nights With Kapil 2.3 (2.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Dance Plus 1.9 (1.6) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Jhalak Dikhhla Jaa Reloaded 1.6 (1.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The Anupam Kher Show .4, (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Lowest Ranking shows [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Qubool Hai 0.9 (1), Baalveer 0.9, Fear Files 0.9 (.9) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Tere Sheher Mein 0.8 (1), Tum Hi Bandhu 0.8 (.7), Badi Dooor Se Aaye Hain 0.8,(.7), Piya Rangrezz 0.8 (.8) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Dream Girl 0.7 (.8), Supercops Vs Supervillains 0.7 (0.5) Sarojini 0.7 (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Zindagi Abhi Baaki Hai Mere Ghost 0.6, (.7), Mohi 0.6 (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Yum Hai Hum 0.5 (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Daffa 420 0.3 (0.4) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Gulmohar Grand 0.2 (.1),  Krishna Kanhaiya 0.2, (0.2), Roshini- 0.2, Comedy Superstars 0.2 (3) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Top channels of the week [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Zee TV 7264 /4.8 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Colors 6184/4.1 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Star Plus 5782/3.8 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Colors 5739/3.8 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Colors 5643/3.7 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "SAN MARCOS, Texas -- A teenager died from what police are calling a \"chokehold\" at a sleepover in Hays County Sunday. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Officers responded to a house in the 100 block ofÂ Farm House Road in the Blanco Vista Subdivision, where CPR was in progress on a victim. After investigating, the officers discovered that seven friendsÂ -- both male and female Hays High School students --Â were having a sleepover or hanging out at the house. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Two of the boys got into a game of wrestling, according to police.Â At some point, one boy got 17-year-old Elijah Hernandez into a chokeÂ hold and told him to tap out. Police saidÂ Hernandez did not tap out and passed out. That's when the kids realized that Hernandez was not breathing, his lips were turning blue and he was not responsive. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The group woke up the parents and the father immediately began CPR. Police and EMS responded, and Hernandez was taken to Seton Hospital in Kyle where he was pronounced dead. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "What we have here are juxtapositions of Michael Slager and Walter Scott that appeared in ranking news stories. The examples are interesting in illustrating how, through distributed or pick-up photography, the visual media will visually represent and often stereotype by role, circumstance and manner as well as ethnicity and race. The photo of “Slager in “the other uniform” comes from his booking photo.  As for Scott, some might argue that the photos in the forth and fifth examples are fairly ambiguous. Others will feel differently given expression, pose, clothing or even the image quality. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "I’ve supplied the article titles, links, image captions and credits. Most significantly, I encourage you to compare and appreciate sensitive drawing  [ 0.  0.  0.]\n",
      "Nailed it\n",
      "from Colorlines [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 12112 , from an ongoing  [ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "r = filter(lambda x: Y[x]>0 , range(X.shape[0]))\n",
    "ind = range(X.shape[0])\n",
    "random.shuffle(ind)\n",
    "rtrain = r[:int(len(r)/2)]+ind[:int(len(r)/2)]\n",
    "rtest = r[int(len(r)/2):]+ind[int(len(r)/2):]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(**{'C': 0.7, 'class_weight': {0: 1, 1: 5}})\n",
    "clf.fit(X[rtrain,:], Y[rtrain])\n",
    "for i,each,y in zip(rtest,clf.predict(X[rtest,:]),Y[rtest]):\n",
    "    if each == 1 and each ==y:\n",
    "        print trainvalues[i], X[i,[1,2,3]]\n",
    "        print 'Nailed it'\n",
    "    if each != y:\n",
    "        print each,y, i, trainvalues[i], X[i,[1,2,3]]\n",
    "        raw_input()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
