{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "65194\n",
      "(65194, 214)\n",
      "No of positive examples 3803\n",
      "Total number of examples 65194\n"
     ]
    }
   ],
   "source": [
    "#Data Analysis\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "trainexamples = []\n",
    "testexamples = []\n",
    "\n",
    "def loadtest(direc):\n",
    "    for each in os.listdir(direc):        \n",
    "        if '.npy' in each:\n",
    "            fids = each.split('_')[1][:-4]\n",
    "            examples = np.load(direc+'/'+each)\n",
    "            with codecs.open(direc+'/'+each[:-4]+'.json', 'r','utf-8') as infile:\n",
    "                values = json.load(infile)\n",
    "            assert(len(examples) == len(values))\n",
    "            yield examples,fids,values\n",
    "    return\n",
    "\n",
    "   \n",
    "def load(direc):\n",
    "    examples = []\n",
    "    fids  = []\n",
    "    values = []\n",
    "    for each in os.listdir(direc):        \n",
    "        try:\n",
    "            if '.npy' in each:\n",
    "                fids.append(each.split('_')[1][:-4])\n",
    "                examples.extend(np.load(direc+'/'+each))\n",
    "                with open(direc+'/'+each[:-4]+'.json', 'r') as infile:\n",
    "                    values.extend(json.load(infile))\n",
    "        except:\n",
    "            continue\n",
    "    return examples,fids,values\n",
    "\n",
    "trainexamples, trainfids, trainvalues = load('../../../data/Contentfeature/train')\n",
    "\n",
    "trainlabels, trainfeatures = [], []\n",
    "for each in trainexamples:\n",
    "    trainfeatures.append(each[1:])\n",
    "    trainlabels.append(each[0])\n",
    "\n",
    "assert(len(trainvalues)==len(trainlabels))\n",
    "print len(trainfeatures[0])\n",
    "print len(trainfeatures)\n",
    "\n",
    "X = np.array(trainfeatures)\n",
    "print X.shape\n",
    "Y = map(lambda x: 1 if x==2 else 0, trainlabels )\n",
    "Y = np.array(Y)\n",
    "print 'No of positive examples %d' %Y.nonzero()[0].shape[0]\n",
    "print 'Total number of examples %d'%Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "FeatureNames\n",
      "next_tag=footer\n",
      "ancestorTag=i\n",
      "next_tag=fieldset\n",
      "next_tag=marquee\n",
      "ancestorTag=b\n",
      "ancestorTag=a\n",
      "data-font-size=12px\n",
      "next_tag=iframe\n",
      "next_tag=nav\n",
      "word_count\n",
      "parent_tag=ul\n",
      "ancestorTag=p\n",
      "parent_tag=center\n",
      "ancestorTag=u\n",
      "next_tag=noscript\n",
      "parent_tag=cite\n",
      "previous_tag=ul\n",
      "parent_tag=span\n",
      "previous_tag=cite\n",
      "next_tag=button\n",
      "previous_tag=th\n",
      "previous_tag=ol\n",
      "previous_tag=footer\n",
      "previous_tag=td\n",
      "ancestorTag=input\n",
      "ancestorTag=form\n",
      "ancestorTag=blockquote\n",
      "functional_word_ratio\n",
      "previous_tag=b\n",
      "previous_tag=a\n",
      "next_tag=time\n",
      "previous_tag=fieldset\n",
      "previous_tag=dd\n",
      "previous_tag=i\n",
      "parent_tag=section\n",
      "parent_tag=aside\n",
      "parent_tag=th\n",
      "next_tag=select\n",
      "parent_tag=td\n",
      "previous_tag=dt\n",
      "previous_tag=nav\n",
      "parent_tag=time\n",
      "next_tag=cite\n",
      "next_tag=ol\n",
      "parent_tag=i\n",
      "previous_tag=center\n",
      "next_tag=td\n",
      "next_tag=include\n",
      "next_tag=th\n",
      "previous_tag=label\n",
      "next_tag=option\n",
      "class=header\n",
      "previous_tag=li\n",
      "next_tag=figure\n",
      "next_tag=table\n",
      "next_tag=b\n",
      "next_tag=a\n",
      "next_tag=img\n",
      "ancestorTag=font\n",
      "next_tag=i\n",
      "ancestorTag=header\n",
      "previous_tag=span\n",
      "next_tag=header\n",
      "parent_tag=bold\n",
      "parent_tag=div\n",
      "ancestorTag=ul\n",
      "parent_tag=font\n",
      "parent_tag=dt\n",
      "previous_tag=strong\n",
      "next_tag=__empty__\n",
      "ancestorTag=em\n",
      "next_tag=base\n",
      "parent_tag=br\n",
      "previous_tag=time\n",
      "parent_tag=blockquote\n",
      "next_tag=hr\n",
      "ancestorTag=bold\n",
      "next_tag=picture\n",
      "parent_tag=em\n",
      "previous_tag=__empty__\n",
      "previous_tag=input\n",
      "previous_tag=small\n",
      "ancestorTag=th\n",
      "next_tag=comments\n",
      "ancestorTag=label\n",
      "next_tag=script\n",
      "ancestorTag=span\n",
      "ancestorTag=option\n",
      "ancestorTag=td\n",
      "ancestorTag=time\n",
      "previous_tag=select\n",
      "parent_tag=u\n",
      "ancestorTag=dd\n",
      "parent_tag=option\n",
      "parent_tag=p\n",
      "data-font-size=16px\n",
      "next_tag=h4\n",
      "next_tag=blockquote\n",
      "next_tag=h6\n",
      "ancestorTag=div\n",
      "next_tag=h1\n",
      "next_tag=h2\n",
      "next_tag=h3\n",
      "ancestorTag=li\n",
      "ancestorTag=dt\n",
      "next_tag=meta\n",
      "next_tag=span\n",
      "parent_tag=a\n",
      "ancestorTag=button\n",
      "previous_tag=style\n",
      "previous_tag=abbr\n",
      "parent_tag=label\n",
      "parent_tag=commentscount\n",
      "previous_tag=legend\n",
      "previous_tag=bold\n",
      "next_tag=br\n",
      "next_tag=label\n",
      "parent_tag=small\n",
      "functional_word_count\n",
      "ancestorTag=textarea\n",
      "previous_tag=br\n",
      "previous_tag=img\n",
      "next_tag=optgroup\n",
      "ancestorTag=abbr\n",
      "previous_tag=h4\n",
      "previous_tag=h5\n",
      "previous_tag=h6\n",
      "parent_tag=sup\n",
      "previous_tag=h1\n",
      "previous_tag=h2\n",
      "previous_tag=h3\n",
      "next_tag=textarea\n",
      "next_tag=small\n",
      "parent_tag=abbr\n",
      "ancestorTag=comment()\n",
      "ancestorTag=ssname\n",
      "next_tag=article\n",
      "previous_tag=button\n",
      "previous_tag=p\n",
      "data-font-size=14px\n",
      "previous_tag=div\n",
      "next_tag=thead\n",
      "parent_tag=ssname\n",
      "previous_tag=textarea\n",
      "parent_tag=caption\n",
      "ancestorTag=cite\n",
      "displaytext=Email\n",
      "previous_tag=figcaption\n",
      "next_tag=abbr\n",
      "ancestorTag=br\n",
      "ancestorTag=strong\n",
      "previous_tag=table\n",
      "previous_tag=header\n",
      "previous_tag=noscript\n",
      "displaytext=Tweet\n",
      "previous_tag=form\n",
      "previous_tag=option\n",
      "class=content\n",
      "previous_tag=em\n",
      "mspam\n",
      "displaytext=Facebook\n",
      "next_tag=section\n",
      "next_tag=p\n",
      "parent_tag=dd\n",
      "ancestorTag=h4\n",
      "ancestorTag=h5\n",
      "ancestorTag=h6\n",
      "parent_tag=textarea\n",
      "ancestorTag=h1\n",
      "ancestorTag=h2\n",
      "ancestorTag=h3\n",
      "next_tag=strong\n",
      "next_tag=svg\n",
      "next_tag=figcaption\n",
      "previous_tag=svg\n",
      "next_tag=li\n",
      "parent_tag=form\n",
      "parent_tag=comment\n",
      "next_tag=h5\n",
      "ancestorTag=comments-count\n",
      "previous_tag=section\n",
      "parent_tag=input\n",
      "next_tag=ul\n",
      "next_tag=dd\n",
      "previous_tag=hr\n",
      "parent_tag=li\n",
      "next_tag=menu\n",
      "parent_tag=button\n",
      "ancestorTag=section\n",
      "previous_tag=blockquote\n",
      "parent_tag=h\n",
      "ancestorTag=small\n",
      "next_tag=aside\n",
      "previous_tag=script\n",
      "previous_tag=aside\n",
      "previous_tag=figure\n",
      "previous_tag=picture\n",
      "ancestorTag=center\n",
      "previous_tag=address\n",
      "previous_tag=meta\n",
      "next_tag=input\n",
      "ancestorTag=sup\n",
      "ancestorTag=legend\n",
      "next_tag=form\n",
      "parent_tag=b\n",
      "parent_tag=legend\n",
      "ancestorTag=aside\n",
      "next_tag=div\n",
      "previous_tag=link\n",
      "ancestorTag=caption\n",
      "next_tag=style\n",
      "parent_tag=strong\n",
      "parent_tag=header\n",
      "next_tag=em\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "#################### SVC  ###############################\n",
      "#################### LOGISTIC REGRESSION ###############################\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.8s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   1.2s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   1.2s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   1.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 15} ..............................\n",
      "[CV] ..................... C=1000, class_weight={0: 1, 1: 15} -   0.9s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.6s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.7s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.8s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.6s\n",
      "[CV] C=50, class_weight={0: 1, 1: 5} .................................\n",
      "[CV] ........................ C=50, class_weight={0: 1, 1: 5} -   0.8s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.3s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.4s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.4s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.4s\n",
      "[CV] C=0.7, class_weight={0: 1, 1: 5} ................................\n",
      "[CV] ....................... C=0.7, class_weight={0: 1, 1: 5} -   0.4s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.8s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.8s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.9s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.7s\n",
      "[CV] C=100, class_weight={0: 1, 1: 15} ...............................\n",
      "[CV] ...................... C=100, class_weight={0: 1, 1: 15} -   0.7s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 15} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 15} -   0.2s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.9s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.7s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.8s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.7s\n",
      "[CV] C=50, class_weight={0: 1, 1: 10} ................................\n",
      "[CV] ....................... C=50, class_weight={0: 1, 1: 10} -   0.8s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.4s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.4s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.3s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.4s\n",
      "[CV] C=0.6, class_weight={0: 1, 1: 10} ...............................\n",
      "[CV] ...................... C=0.6, class_weight={0: 1, 1: 10} -   0.4s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.4s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.3s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.3s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.3s\n",
      "[CV] C=0.9, class_weight={0: 1, 1: 1} ................................\n",
      "[CV] ....................... C=0.9, class_weight={0: 1, 1: 1} -   0.4s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  41 jobs       | elapsed:   23.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.2s\n",
      "[CV] C=0.001, class_weight={0: 1, 1: 10} .............................\n",
      "[CV] .................... C=0.001, class_weight={0: 1, 1: 10} -   0.2s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   1.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   1.0s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.7s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.8s\n",
      "[CV] C=1000, class_weight={0: 1, 1: 5} ...............................\n",
      "[CV] ...................... C=1000, class_weight={0: 1, 1: 5} -   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.00 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.697 (std: 0.004)\n",
      "Parameters: {'C': 0.7, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.696 (std: 0.005)\n",
      "Parameters: {'C': 50, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.696 (std: 0.005)\n",
      "Parameters: {'C': 1000, 'class_weight': {0: 1, 1: 5}}\n",
      "\n",
      "Continue ??\n",
      "d\n",
      "#################### RANDOM FOREST ###############################\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 -   0.5s\n",
      "[CV] bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 -   0.4s\n",
      "[CV] bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=2, min_samples_split=8, criterion=gini, max_features=4, max_depth=3 -   0.4s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 -   0.6s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 -   0.6s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=5, criterion=entropy, max_features=7, max_depth=3 -   0.5s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None -   2.0s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None -   1.9s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=3, criterion=entropy, max_features=5, max_depth=None -   2.1s\n",
      "[CV] bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 -   0.7s\n",
      "[CV] bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 -   0.7s\n",
      "[CV] bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 \n",
      "[CV]  bootstrap=False, min_samples_leaf=6, min_samples_split=10, criterion=gini, max_features=10, max_depth=3 -   0.7s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None -   2.1s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None -   2.2s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=1, criterion=gini, max_features=5, max_depth=None -   2.9s\n",
      "[CV] bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None \n",
      "[CV]  bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None -   2.2s\n",
      "[CV] bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None \n",
      "[CV]  bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None -   1.9s\n",
      "[CV] bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None \n",
      "[CV]  bootstrap=False, min_samples_leaf=8, min_samples_split=10, criterion=gini, max_features=7, max_depth=None -   1.7s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 -   0.6s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 -   0.5s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=9, criterion=gini, max_features=9, max_depth=3 -   0.5s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None -   2.4s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None -   1.9s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=4, criterion=entropy, max_features=3, max_depth=None -   1.9s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 -   0.3s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 -   0.3s\n",
      "[CV] bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=1, min_samples_split=7, criterion=entropy, max_features=2, max_depth=3 -   0.3s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 -   0.3s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 -   0.3s\n",
      "[CV] bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 \n",
      "[CV]  bootstrap=True, min_samples_leaf=4, min_samples_split=6, criterion=gini, max_features=2, max_depth=3 -   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   33.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 36.24 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.668 (std: 0.038)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 8, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 7, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.652 (std: 0.028)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 4, 'criterion': 'entropy', 'max_features': 3, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.641 (std: 0.024)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "BestParams and score\n",
      "[({'C': 0.7, 'class_weight': {0: 1, 1: 5}}, 0.69743675917283288), ({'bootstrap': False, 'min_samples_leaf': 8, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 7, 'max_depth': None}, 0.66848235546443358)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('../../../data/Contentfeature/train/featurenames.json') as infile:\n",
    "    featurenames = json.load(infile)\n",
    "assert(len(featurenames) == len(trainfeatures[0]))\n",
    "\n",
    "\n",
    "################ ML methods ######################################\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from time import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "d = dict(zip(featurenames,range(len(featurenames))))\n",
    "print '-----------------'*10\n",
    "print 'FeatureNames'\n",
    "for each in d.keys():\n",
    "    print each\n",
    "print '-----------------'*10\n",
    "###################################################################################################################\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        if i == 0:\n",
    "            bestparams = (score.parameters,score.mean_validation_score)\n",
    "        print(\"\")\n",
    "    return bestparams\n",
    "\n",
    "def getf1score(estimator, X, Y):\n",
    "    #return recall_score(estimator.predict(X),Y)\n",
    "    return f1_score(estimator.predict(X),Y)\n",
    "\n",
    "\n",
    "\n",
    "clf1 = SVC(C=1.0)\n",
    "clf2 = LogisticRegression(penalty='l2', random_state=4,C=1.0)\n",
    "clf3 = RandomForestClassifier(n_estimators=20)\n",
    "s3fold = StratifiedKFold(y=Y, n_folds=5,\n",
    "                                         shuffle=True, random_state=2)\n",
    "bestparams = []\n",
    "\n",
    "C = [0.001, 0.001, 0.1, 0.7, 0.5, 0.6, 0.9, 1, 2, 5, 7, 10,50, 70, 100,1000]\n",
    "gamma = [0.00001, 0.0001,0.001, 0.01, 0.1]\n",
    "class_weights = [{0:1,1:1},{0:1,1:5},{0:1,1:10},{0:1,1:15},{0:1,1:20}]\n",
    "\n",
    "param_dist = {\"C\": C, \"gamma\":gamma, \"class_weight\":class_weights}\n",
    "\n",
    "Xnew = X\n",
    "\n",
    "\n",
    "print '#################### SVC  ###############################'\n",
    "np.random.seed(5)\n",
    "# # run randomized search\n",
    "n_iter_search = 20\n",
    "# random_search = RandomizedSearchCV(clf1, param_distributions=param_dist, scoring=getf1score,\n",
    "#                                    verbose=2, cv=s3fold )\n",
    "# start = time()\n",
    "# random_search.fit(Xnew, Y)\n",
    "# print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "#       \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "# bestparams.append(report(random_search.grid_scores_))\n",
    "# print 'Continue ??'\n",
    "# raw_input()\n",
    "\n",
    "param_dist = {\"C\": C,\"class_weight\": class_weights}\n",
    "print '#################### LOGISTIC REGRESSION ###############################'\n",
    "random_search = RandomizedSearchCV(clf2, param_distributions=param_dist, scoring=getf1score,\n",
    "                                   verbose=2 ,cv=s3fold)\n",
    "\n",
    "random_search.fit(Xnew, Y)\n",
    "start = time()\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "bestparams.append(report(random_search.grid_scores_))\n",
    "print 'Continue ??'\n",
    "raw_input()\n",
    "\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "print '#################### RANDOM FOREST ###############################'\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "random_search = RandomizedSearchCV(clf3, param_distributions=param_dist, scoring=getf1score,\n",
    "                                   verbose=2 )\n",
    "\n",
    "\n",
    "start = time()\n",
    "random_search.fit(Xnew, Y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "bestparams.append(report(random_search.grid_scores_))\n",
    "print 'BestParams and score'\n",
    "print bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic regression\n",
      "F1 score 0.6948\n",
      "Recall score 0.6105\n",
      "Precision score 0.8060\n",
      "2511 1902\n",
      "\n",
      "Pickling...\n",
      "Done pickling..\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(124)  \n",
    "np.random.seed(124)\n",
    "clf = LogisticRegression(**{'C': 0.7, 'class_weight': {0: 1, 1: 5}})\n",
    "\n",
    "rpos = filter(lambda x: Y[x]>0, range(Y.shape[0]))\n",
    "rneg = filter(lambda x: Y[x]==0, range(Y.shape[0]))\n",
    "\n",
    "random.shuffle(rpos)\n",
    "random.shuffle(rneg)\n",
    "\n",
    "rtrain = rpos[:int(len(rpos)/2)]+rneg[:int(len(rneg)/2)]\n",
    "rtest = rpos[int(len(rpos)/2):]+rneg[int(len(rneg)/2):]\n",
    "random.shuffle(rtrain)\n",
    "random.shuffle(rtest)\n",
    "print 'Logisitic regression'\n",
    "\n",
    "clf.fit(X[rtrain,:],Y[rtrain])\n",
    "res = []\n",
    "for i in range(len(featurenames)): res.append((clf.coef_[0,i],featurenames[i]))\n",
    "topk = 10\n",
    "values = []\n",
    "values.extend(sorted(res)[:topk])\n",
    "values.extend(sorted(res)[-topk:])\n",
    "topk *=2\n",
    "values,labels = zip(*values)\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "width= 0.8\n",
    "ax.bar(range(topk), values, width=width)\n",
    "ax.set_xticks(np.arange(topk) + width/2)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "ax.set_title('Top %s discrimenatory features vs weight' %topk)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print 'F1 score %.4f' %f1_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "print 'Recall score %.4f' %recall_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "print 'Precision score %.4f' %precision_score(clf.predict(X[rtest,:]),Y[rtest])\n",
    "\n",
    "print len(clf.predict(X[rtest,:]).nonzero()[0]),len(Y[rtest].nonzero()[0])\n",
    "print \n",
    "\n",
    "print 'Pickling...'\n",
    "clf.fit(X,Y)\n",
    "pickle.dump(clf, file('../../../data/Contentfeature/train/Content.classifier','w'))\n",
    "print 'Done pickling..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYSIS..\n",
      "Samples gone wrong\n",
      "\n",
      "Fire investigator Craig Bain said after initial investigations it appeared there were no working smoke alarms in the house. He said it is believed the fire started in the back bedroom of the two-bedroom house, where the man's body was found. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "\n",
      "Mr Henwood said as the festive season nears it was a reminder for people with elderly relatives living alone to check on them, and ensure they had working smoke alarms fitted. The cause of the fire was still being investigated as of yesterday but Mr Bain said it was not being treated as suspicious. [ 0.  0.  0.]\n",
      "Nailed it\n",
      " The U.S. Department of Justice has awarded the City of Killeen a $1.625 million Community Oriented Policing Services grant that will fund 13 new police officers, U.S. Rep. John Carter, R-Round Rock, announced Tuesday.                                              [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The COPS grants are awarded to local law enforcement agencies to fund new officers to help with community crime prevention efforts. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "A total of $113 million was awarded to 209 agencies during the 2015 grant cycle, Carter said. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The Killeen Police Department received a $1.8 million COPS grant in 2010 for 10 officers and another $1.5 million in 2014 for 13 officers. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Star Plus was the number one channel since a while but Colors TV has taken over. Here is the BARC report for week 36! [ 0.  0.  0.]\n",
      "Nailed it\n",
      " was the number one show last week and is this week as well! [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Last week, Star Plus had regained it’s spot as the number one spot and outdone Colors TV. But the latter is on top once again, followed by Star Plus. Kumkum Bhagya is the number one show yet again, followed by Meri Aashiqui Tumse Hi. New show Swaragini is slowly making it’s mark in the TRP charts and has earned the 3rd position this time. Star Plus’s Yeh Hai Mohabbatein has not seen any major improvement and shockingly, ZEE TV’s Qubool Hai is one of the lowest ranking shows this week. Here’s the  [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 33361 BARC report  [ 0.  0.  0.]\n",
      "d\n",
      "0 1 33362 for week 36! [ 0.  0.  0.]\n",
      "f\n",
      "Top ten shows (TRPs) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Kumkum Bhagya  4.8 (4.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Meri Aashiqui Meri Aashiqui 4 (3.8) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Swaragini 3.8 (3.6), Sasural Simar 3.6 (3.6,  Saath Nibhaana Saathiya 3.8 (3.6) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Udaan 3.7 (3.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Balika Vadhu 3.3 (3),  Yeh Hai Mohabbatein 3.3 (3.1) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Ashoka Samrat 3.1, (3.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Yeh Rishta Kya Kehlata Hai  2.5 (2.7), Tarak Mehta Ka Oolta Chashma 2.5, (2.6) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Suhani Si Ek Ladki  2.4 (2.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Thapki Pyar Ki 2.2, (2.1) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Jamai  Raja 2.1 (1.9), Satrangi Sasural  2.1 (2.2) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Reality Shows (TRPs) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Comedy Nights Bachao 3.4 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Comedy Nights With Kapil 2.3 (2.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Dance Plus 1.9 (1.6) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Jhalak Dikhhla Jaa Reloaded 1.6 (1.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The Anupam Kher Show .4, (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Lowest Ranking shows [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Qubool Hai 0.9 (1), Baalveer 0.9, Fear Files 0.9 (.9) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Tere Sheher Mein 0.8 (1), Tum Hi Bandhu 0.8 (.7), Badi Dooor Se Aaye Hain 0.8,(.7), Piya Rangrezz 0.8 (.8) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Dream Girl 0.7 (.8), Supercops Vs Supervillains 0.7 (0.5) Sarojini 0.7 (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Zindagi Abhi Baaki Hai Mere Ghost 0.6, (.7), Mohi 0.6 (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Yum Hai Hum 0.5 (.5) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Daffa 420 0.3 (0.4) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Gulmohar Grand 0.2 (.1),  Krishna Kanhaiya 0.2, (0.2), Roshini- 0.2, Comedy Superstars 0.2 (3) [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Top channels of the week [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Zee TV 7264 /4.8 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Colors 6184/4.1 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Star Plus 5782/3.8 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Colors 5739/3.8 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Colors 5643/3.7 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "BREAKING NEWS UPDATE: Police are responding to shots fired at OP Avenue and 6th Street in Texas Township, near the Cracker Barrel. There is police involvement at the scene, Kalamazoo County undersheriff says. Unclear if cops or possible suspect opened fire. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "—– [ 0.  0.  0.]\n",
      "Nailed it\n",
      "TEXAS TOWNSHIP, Mich. (WOOD) — Police in Kalamazoo County are searching for a suspect who is randomly shooting people, at least six have been killed. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Kalamazoo County Undersheriff Paul Matyas told 24 Hour News 8 that multiple were fatally shot at the Cracker Barrel in Texas Township and Seelye Kia dealership, located at 3820 Stadium Drive in Kalamazoo. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Matyas says the suspect is driving around randomly shooting people. Police believe the suspect is white man who is driving a blue Chevy HHR. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Police say four people were killed at the Cracker Barrel and one was taken to the hospital in critical condition. An eight-year-old child was among the people killed at the restaurant. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Authorities say a father and son were shot and killed at the dealership. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "A woman was  [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 33791 shot multiple times [ 0.  0.  0.]\n",
      "g\n",
      " in the Meadows Townhomes parking lot in Richland Township. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "We have a crew on scene working to find out more information. Check back with woodtv.com for updates. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Police are trying to determine what caused a man to gun down his girlfriend, her sister and another man, killing all three, before taking his own life in central Maine. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "OAKLAND, Maine—Police are trying to determine what caused a man to gun down his girlfriend, her sister and another man, killing all three, before taking his own life in central Maine. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Police say the only survivor was a 3-year-old girl who was unharmed. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Police identified the victims as the child's parents, Amanda Bragg and Michael Muzerolle, along with Bragg's sister, Amy Derosby. They say Derosby's boyfriend, Herman Derico, shot them in an Oakland apartment Wednesday night before killing himself in the driveway. A 9mm handgun was found next his body. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "McCausland says police are trying to determine what sparked the violence. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "He says one of the many 911 calls came from one of the wounded women before she died. He says the little girl is in the care of her grandmother. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "PHOENIX, Ariz. -- [ 0.  0.  0.]\n",
      "Nailed it\n",
      "A priest suspected in a 1960 Texas murder was arrested Tuesday in Scottsdale. The Maricopa County Sheriff's Office confirmed the arrest of Father John Feit,  [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 34066 reports CBS affiliate KPHO [ 0.  0.  0.]\n",
      "f\n",
      "0 1 34067 . [ 0.  0.  0.]\n",
      "as\n",
      "The body of Irene Garza, 25, was found in an irrigation canal in McAllen, Texas in April 1960. The last time anybody saw the beauty queen, she was going to confession at Sacred Heart Catholic Church. Feit, 27 at the time, heard that confession. He was a visiting priest. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "\"48 Hours\" aired a story about the case -- \"The Last Confession\" -- on March 1, 2014 [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 34075 . The story was updated on July 26 that year. [ 0.  0.  0.]\n",
      "d\n",
      "Feit now faces a murder charge in Garza's death, and is awaiting extradition to Texas, officials said. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Hidalgo County District Attorney Ricardo Rodriguez said he presented the case against Feit to a grand jury last week.\tRicardo said: \"We felt that we had sufficient evidence to present to a grand jury. It was presented last week, and they came back with a true bill.\" [ 0.  0.  0.]\n",
      "Nailed it\n",
      "While police interviewed hundreds of people in connection with Garza's murder, Feit was their focus. He was the last person to see Garza alive. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "As the investigation continued, another young woman came forward and said Feit attacked her three weeks before Garza's murder. Feit was tried in 1961, but the jury deadlocked. To avoid another trial, he pleaded guilty to a lesser charge and was fined $500. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Fast forward to 2002. Texas Ranger Rudy Jaramillo got information about a new witness, a former monk. That monk said Feit told him during counseling sessions about attacking Garza. Feit later claimed not remember the conversation and denied killing Garza. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Another priest later said Feit had told him the same thing. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Garza's family has been pushing the Hidalgo County District Attorney's Office for years to move on the case, demanding justice for Garza. It never happened. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Feit, now an 81-year-old grandfather, has been living in a Scottsdale retirement community. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The circumstances of Feit's arrest were not immediately available. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "He will be extradited to Texas, but it's not clear when. If Feit waives extradition, it will happen quickly. If he does not, the process will take longer. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "SAN MARCOS, Texas -- A teenager died from what police are calling a \"chokehold\" at a sleepover in Hays County Sunday. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Officers responded to a house in the 100 block ofÂ Farm House Road in the Blanco Vista Subdivision, where CPR was in progress on a victim. After investigating, the officers discovered that seven friendsÂ -- both male and female Hays High School students --Â were having a sleepover or hanging out at the house. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Two of the boys got into a game of wrestling, according to police.Â At some point, one boy got 17-year-old Elijah Hernandez into a chokeÂ hold and told him to tap out. Police saidÂ Hernandez did not tap out and passed out. That's when the kids realized that Hernandez was not breathing, his lips were turning blue and he was not responsive. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The group woke up the parents and the father immediately began CPR. Police and EMS responded, and Hernandez was taken to Seton Hospital in Kyle where he was pronounced dead. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "LAS VEGAS (KSNV News 3LV) [ 0.  0.  0.]\n",
      "Nailed it\n",
      " – A man is dead after being shot in the 4800 block of East Sahara and Nellis Road. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "It happened around 4:15 PM Thursday evening. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Sgt. Matthew Sanford with the LVMPD says they received a call of shots fired inside an apartment complex in the 4800 block of East Sahara. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "When officers arrived, they found the man suffering from gunshot wounds inside an apartment. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The man was transported to Sunrise Hospital where he later died. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "Investigators say there was some type of argument before the shooting started. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "The police are searching for a man accused of menacing a Brooklyn subway rider with a knife on Sunday. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "What we have here are juxtapositions of Michael Slager and Walter Scott that appeared in ranking news stories. The examples are interesting in illustrating how, through distributed or pick-up photography, the visual media will visually represent and often stereotype by role, circumstance and manner as well as ethnicity and race. The photo of “Slager in “the other uniform” comes from his booking photo.  As for Scott, some might argue that the photos in the forth and fifth examples are fairly ambiguous. Others will feel differently given expression, pose, clothing or even the image quality. [ 0.  0.  0.]\n",
      "Nailed it\n",
      "I’ve supplied the article titles, links, image captions and credits. Most significantly, I encourage you to compare and appreciate sensitive drawing  [ 0.  0.  0.]\n",
      "Nailed it\n",
      "0 1 34556 from Colorlines [ 0.  0.  0.]\n",
      "d\n",
      "0 1 34557 , from an ongoing  [ 0.  0.  0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-20787e158af9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meach\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gowthamrang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         )\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gowthamrang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print 'ANALYSIS..'\n",
    "r = filter(lambda x: Y[x]>0 , range(X.shape[0]))\n",
    "ind = range(X.shape[0])\n",
    "random.shuffle(ind)\n",
    "rtrain = r[:int(len(r)/2)]+ind[:int(len(r)/2)]\n",
    "rtest = r[int(len(r)/2):]+ind[int(len(r)/2):]\n",
    "print 'Samples gone wrong'\n",
    "\n",
    "clf = LogisticRegression(**{'C': 0.7, 'class_weight': {0: 1, 1: 5}})\n",
    "clf.fit(X[rtrain,:], Y[rtrain])\n",
    "for i,each,y in zip(rtest,clf.predict(X[rtest,:]),Y[rtest]):\n",
    "    if each == 1 and each ==y:\n",
    "        print trainvalues[i], X[i,[1,2,3]]\n",
    "        print 'Nailed it'\n",
    "    if each != y:\n",
    "        print each,y, i, trainvalues[i], X[i,[1,2,3]]\n",
    "        raw_input()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
